{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "030d60da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willb\\Documents\\Projetos\\DataThon-Fiap\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\willb\\Documents\\Projetos\\DataThon-Fiap\\venv\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "import settings\n",
    "import torch\n",
    "from ollama import chat, ChatResponse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6821d5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base de conhecimento (exemplo simples)\n",
    "docs = '''Sou analista de dados, bacharel em Sistemas de Informação e atualmente curso uma\n",
    " pós-graduação em Engenharia de Machine Learning. Meu foco está na análise e\n",
    " engenharia de dados, além da automação de processos, sempre buscando\n",
    " transformar dados complexos em informações estratégicas e garantir soluções\n",
    " eficientes. Combino criatividade e pensamento analítico com senso de urgência,\n",
    " proatividade e trabalho em equipe para enfrentar desafios com foco e resiliência,\n",
    " enquanto aprimoro constantemente minhas habilidades técnicas e de liderança.\n",
    " No meu cargo atual, desenvolvo scripts em Python para criar sistemas internos, extrair\n",
    " dados via web scraping e automatizar tarefas rotineiras. Além disso, trabalho com\n",
    " SQL para manipulação eficiente de dados em um ambiente de Big Data, sempre\n",
    " buscando otimizar consultas. Com os dados refinados, crio painéis interativos e\n",
    " visualizações no Power BI e outras ferramentas, transformando conjuntos de dados\n",
    " complexos em insights acionáveis que auxiliam na tomada de decisões em diversas\n",
    " áreas do negócio.\n",
    " Python (Avançado)\n",
    " SQL (Avançado)\n",
    " Sistemas de Data Viz\n",
    " Inglês Fluente\n",
    " Metodologias Ágeis\n",
    " Docker\n",
    " Spark\n",
    " Algoritmos de\n",
    " Modelagem'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb139cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description = '''Job Description\n",
    "\n",
    "Perfil de um Desenvolvedor Python OCI para migrar um Data Lake da AWS para o OCI\n",
    "\n",
    "Desenvolvedor sênior de Python\n",
    "Uso de SDKs (OCI SDK em Python)\n",
    "Experiência no tratamento de dados nos formatos Parquet e JSON\n",
    "Otimização de jobs Spark a nível de código (partições, joins, cache)\n",
    "\n",
    "\n",
    "Serviços OCI\n",
    "\n",
    "OCI Object Storage\n",
    "OCI Data Flow\n",
    "OCI SQL Endpoint\n",
    "OCI SDK para Python\n",
    "OCI Function\n",
    "OCI ADW\n",
    "\n",
    "\n",
    "Responsibilities\n",
    "\n",
    "Descrição das atividades:\n",
    "\n",
    "Gerenciamento de acessos a buckets/objetos.\n",
    "Automação de deployments.\n",
    "Desenvolvimento de scripts para copiar dados entre AWS e OCI (upload/download multipart, paralelismo).\n",
    "Migração de códigos AWS para OCI.\n",
    "Configuração do Data Flow.\n",
    "Consultas em SQL Endpoint.\n",
    "Validações pós-migração.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ff547e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_query_optimized(curriculo, job_description, top_k=2):  \n",
    "    # --- 2) Criar prompt otimizado ---\n",
    "    prompt = f\"\"\"\n",
    "    Contexto:\n",
    "    Sua tarefa é ler o texto do currículo de um candidato e a descrição da vaga e gerar exatamente:\n",
    "\n",
    "    1. Cinco pontos de destaque do candidato, em frases curtas e diretas (máximo 2 linhas cada), resumindo experiências, conquistas, habilidades e competências mais relevantes para a vaga.\n",
    "    2. Cinco perguntas estratégicas para entrevista, que explorem motivação, comportamento, soft skills, competências ou requisitos da vaga que não aparecem claramente no currículo.\n",
    "\n",
    "    Instruções obrigatórias (siga à risca):\n",
    "    - Use apenas informações do currículo e da vaga. Não invente fatos.\n",
    "    - Seja objetivo, claro e direto nos pontos de destaque (formato de mini resumo).\n",
    "    - As perguntas devem ser diferentes entre si, relevantes para a vaga e incentivar respostas com exemplos concretos.\n",
    "    - Nenhum ponto de destaque pode ser repetido.\n",
    "    - Nenhuma pergunta pode ser repetida.\n",
    "    - Nenhuma pergunta pode repetir informações já abordadas nos pontos de destaque.\n",
    "    - Considere experiências passadas, formação acadêmica, habilidades técnicas e comportamentais.\n",
    "    - Não retorne o texto de entrada, nem o contexto, nem explicações adicionais.\n",
    "\n",
    "    - A saída deve estar **exclusivamente em formato JSON seguindo o template abaixo, sem qualquer texto fora dele:\n",
    "\n",
    "    ```json\n",
    "      \"pontos_de_destaque\": [\n",
    "        \"Resumo curto do ponto 1\",\n",
    "        \"Resumo curto do ponto 2\",\n",
    "        \"Resumo curto do ponto 3\",\n",
    "        \"Resumo curto do ponto 4\",\n",
    "        \"Resumo curto do ponto 5\"\n",
    "      ],\n",
    "      \"perguntas_entrevista\": [\n",
    "        \"Pergunta 1\",\n",
    "        \"Pergunta 2\",\n",
    "        \"Pergunta 3\",\n",
    "        \"Pergunta 4\",\n",
    "        \"Pergunta 5\"\n",
    "      ]\n",
    "    ```\n",
    "      \n",
    "    Entrada: \n",
    "\n",
    "    Currículo:\n",
    "    {curriculo}\n",
    "\n",
    "    Vaga:\n",
    "    {job_description}\n",
    "\n",
    "    \"\"\"\n",
    "    response: ChatResponse = chat(model='gemma3:4b', messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Você é um assistente de recrutamento virtual.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ])\n",
    "\n",
    "    return response.message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e5b9d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"pontos_de_destaque\": [\n",
      "    \"Possui formação em Sistemas de Informação e está aprofundando seus conhecimentos em Machine Learning, demonstrando um compromisso com o aprendizado contínuo.\",\n",
      "    \"Desenvolve scripts em Python para criação de sistemas internos e web scraping, indicando habilidades em programação e coleta de dados.\",\n",
      "    \"Apresenta experiência em manipulação de dados em formatos Parquet e JSON, crucial para o trabalho com Data Lakes.\",\n",
      "    \"Utiliza SQL Endpoint e Power BI para criação de painéis interativos e visualizações de dados, otimizando a análise de informações.\",\n",
      "    \"Desenvolve e otimiza jobs Spark para a migração de dados, evidenciando conhecimento em Big Data e performance de código.\"\n",
      "  ],\n",
      "  \"perguntas_entrevista\": [\n",
      "    \"Descreva uma situação em que você precisou lidar com um problema de performance em um script ou job que estava executando. Quais foram as etapas que você tomou para identificar e resolver o problema?\",\n",
      "    \"Como você abordaria a tarefa de automatizar o processo de cópia de dados entre AWS e OCI, considerando a necessidade de paralelismo e otimização?\",\n",
      "    \"Compartilhe sua experiência em trabalhar com diferentes ferramentas de visualização de dados (Power BI, etc.). Em que situações você escolheria uma ferramenta em detrimento de outra?\",\n",
      "    \"Em relação à segurança de acesso a buckets e objetos no OCI, quais seriam suas prioridades e como garantiria a conformidade com as políticas de segurança da empresa?\",\n",
      "    \"Pense em um projeto onde a tomada de decisões baseada em dados foi fundamental. Qual foi seu papel nesse processo e como você garantiu que os insights gerados fossem utilizados de forma eficaz?\"\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# 4) Testar\n",
    "print(rag_query_optimized(job_description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebbf4e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
